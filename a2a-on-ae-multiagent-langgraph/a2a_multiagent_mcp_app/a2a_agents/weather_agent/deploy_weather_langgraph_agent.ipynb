{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to build, deploy, and interact with **[Agent2Agent (A2A) protocol](https://a2aprotocol.org)** agents hosted on the fully-managed, serverless **Vertex AI Agent Engine**.\n",
    "\n",
    "A2A is an open standard, like HTTP for AI agents, enabling communication and collaboration between diverse AI agents by standardizing capability discovery (via Agent Cards) and interaction for complex tasks, thereby eliminating custom integrations.\n",
    "\n",
    "Vertex AI Agent Engine is fully-managed, serverless platform for running A2A agents. It handles all the infrastructure, scaling, security, and monitoring so you can focus on your agent's logic.\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "* **Build** a simple, A2A-compliant agent using the Vertex AI SDK.  \n",
    "* **Test** the agent locally to ensure it works as expected.  \n",
    "* **Deploy** the agent to Agent Engine with a single command.  \n",
    "* **Query** the managed agent endpoint using three different methods (Vertex AI SDK, A2A SDK, and direct HTTP requests). \n",
    "* **Clean up** the resources you've created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install required packages\n",
    "\n",
    "First, we'll install the necessary packages.\n",
    "\n",
    "- `a2a-sdk` is the foundational open-source SDK for building A2A-compliant agents.\n",
    "- `google-cloud-aiplatform` is the Vertex AI SDK, containing the new Agent Engine template we'll use for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet \"a2a-sdk>=0.3.4\" --force-reinstall --quiet\n",
    "%pip install --upgrade --quiet \"google-cloud-aiplatform[agent_engines, adk]>=1.112.0\" --force-reinstall --quiet\n",
    "%pip install --upgrade --quiet langchain-mcp-adapters starlette langchain_google_vertexai langgraph langchain-openai --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# \n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     from google.colab import auth\n",
    "# \n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "from google.genai import types\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # \n",
    "\n",
    "\n",
    "PROJECT_ID = os.environ.get(\"PROJECT_ID\") # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}
",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-bucket\"   # @param {type: \"string\", placeholder: \"[your-bucket-name]\", isTemplate: true}
",
    "if not BUCKET_NAME or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID\n",
    "\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "# !gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI\n",
    "\n",
    "# Initialize Vertex AI session\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)\n",
    "\n",
    "# Initialize the Gen AI client using http_options with increased timeout\n",
    "# The parameter customizes how the Vertex AI client communicates with Google Cloud's backend services.\n",
    "# It's used here to access new, pre-release features.\n",
    "client = vertexai.Client(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    http_options=types.HttpOptions(\n",
    "        api_version=\"v1beta1\", \n",
    "        base_url=f\"https://{LOCATION}-aiplatform.googleapis.com/\",\n",
    "        timeout=300.0  # 5 minute timeout for Agent Engine operations\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NUMBER = os.environ.get(\"PROJECT_NUMBER\")\n",
    "MCP_SERVER_URL = os.environ.get(\"MCP_SERVER_URL\")\n",
    "GOOGLE_GENAI_MODEL = os.environ.get(\"GOOGLE_GENAI_MODEL\")\n",
    "print(f\"PROJECT_NUMBER: {PROJECT_NUMBER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5303c05f7aa6"
   },
   "source": [
    "### Import libraries\n",
    "\n",
    "Here, we're importing all the necessary Python classes and functions we'll use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fc324893334"
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from collections.abc import Awaitable, Callable\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from typing import Any\n",
    "import httpx\n",
    "from IPython.display import Markdown, display\n",
    "from google.auth import default\n",
    "from google.auth.transport.requests import Request as req\n",
    "from starlette.requests import Request\n",
    "# A2A\n",
    "from a2a.client import ClientConfig, ClientFactory\n",
    "from a2a.types import (\n",
    "    Message,\n",
    "    Part,\n",
    "    Role,\n",
    "    TaskQueryParams,\n",
    "    TextPart,\n",
    "    TransportProtocol,\n",
    ")\n",
    "from google.genai import types\n",
    "# Agent Engine\n",
    "from vertexai.preview.reasoning_engines import A2aAgent\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra6lH9ad3Vkx"
   },
   "source": [
    "### Helpers\n",
    "\n",
    "These are simple utility functions to make our lives easier, especially for local testing. They help create mock HTTP requests (`build_post_request`, `build_get_request`) and fetch authentication tokens (`get_bearer_token`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zH-NZDQ5n9e"
   },
   "outputs": [],
   "source": [
    "def receive_wrapper(data: dict) -> Callable[[], Awaitable[dict]]:\n",
    "    \"\"\"Creates a mock ASGI receive callable for testing.\"\"\"\n",
    "\n",
    "    async def receive():\n",
    "        byte_data = json.dumps(data).encode(\"utf-8\")\n",
    "        return {\"type\": \"http.request\", \"body\": byte_data, \"more_body\": False}\n",
    "\n",
    "    return receive\n",
    "\n",
    "\n",
    "def build_post_request(\n",
    "    data: dict[str, Any] | None = None, path_params: dict[str, str] | None = None\n",
    ") -> Request:\n",
    "    \"\"\"Builds a mock Starlette Request object for a POST request with JSON data.\"\"\"\n",
    "    scope = {\n",
    "        \"type\": \"http\",\n",
    "        \"http_version\": \"1.1\",\n",
    "        \"headers\": [(b\"content-type\", b\"application/json\")],\n",
    "        \"app\": None,\n",
    "    }\n",
    "    if path_params:\n",
    "        scope[\"path_params\"] = path_params\n",
    "    receiver = receive_wrapper(data)\n",
    "    return Request(scope, receiver)\n",
    "\n",
    "\n",
    "def build_get_request(path_params: dict[str, str]) -> Request:\n",
    "    \"\"\"Builds a mock Starlette Request object for a GET request.\"\"\"\n",
    "    scope = {\n",
    "        \"type\": \"http\",\n",
    "        \"http_version\": \"1.1\",\n",
    "        \"query_string\": b\"\",\n",
    "        \"app\": None,\n",
    "    }\n",
    "    if path_params:\n",
    "        scope[\"path_params\"] = path_params\n",
    "\n",
    "    async def receive():\n",
    "        return {\"type\": \"http.disconnect\"}\n",
    "\n",
    "    return Request(scope, receive)\n",
    "\n",
    "\n",
    "def get_bearer_token() -> str | None:\n",
    "    \"\"\"Fetches a Google Cloud bearer token using Application Default Credentials.\"\"\"\n",
    "    try:\n",
    "        # Use an alias to avoid name collision with starlette.requests.Request\n",
    "        credentials, project = default(\n",
    "            scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "        )\n",
    "        request = req()\n",
    "        credentials.refresh(request)\n",
    "        return credentials.token\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting credentials: {e}\")\n",
    "        print(\n",
    "            \"Please ensure you have authenticated with 'gcloud auth application-default login'.\"\n",
    "        )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuFUUkq53kdo"
   },
   "source": [
    "### Build a simple ADK agent\n",
    "\n",
    "Before we can build an A2A agent, we need an agent. We create an agent using the Agent Development Kit (ADK).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from weather_agent import weather_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdoPfLSR6dN1"
   },
   "source": [
    "### Define the agent card\n",
    "\n",
    "AgentCard is an important component of the A2A protocol. Think of it as a digital business card for your agent. It's a structured JSON document that tells other agents everything they need to know to interact with yours: its name, what it does, the skills it offers, and how to call its API endpoint.\n",
    "\n",
    "We define an `AgentSkill` to describe our agent's Q&A capability. Then, we use the `create_agent_card` helper function to assemble the full card, including the agent's name, description, and the skill we just defined.\n",
    "\n",
    "> Note: The utility builds the card based on the limitations in the current integration: Streaming is turned off and supports Authenticated Extended Card is turned on. Also `create_agent_card` supports `agent_card` which allows you to supply an `agent_card` as dictionary. If an Agent Card is supplied as a dictionary, validation errors might show depending on whether the card meets the current integration limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qPvhFCAVpRz"
   },
   "source": [
    "Let's print the AgentCard we just created.\n",
    "\n",
    "Take a look at the structure. You can see key fields like name, description, skills, and the url. For now, the URL points to localhost, which is perfect for local testing. When we deploy to Agent Engine, this URL will be automatically updated to point to the managed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather_agent_card import weather_agent_card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-d-VhZi7RIM"
   },
   "source": [
    "### Define the agent executor\n",
    "\n",
    "The AgentExecutor is the bridge between the A2A protocol and our agent's internal logic. It's a class that you implement to handle incoming A2A requests. It has two main methods:\n",
    "\n",
    "*   `execute`: This is the main entry point. When a message arrives, this method gets the user's query from the RequestContext, creates a TaskUpdater - a handy A2A SDK tool for managing the task's lifecycle (e.g., setting its state to working), calls the ADK Runner to process the query with the Gemini model and Google Search tool, asynchronously waits for the final response from the agent, packages the text response into an A2A Artifact—the official output of a task and finally, marks the task as completed.\n",
    "*   `cancel`: Our simple agent doesn't support long-running, cancelable jobs, so we simply state that the operation is unsupported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_executor import WeatherAgentExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sOxOLNU-Vz6"
   },
   "source": [
    "### Test the agent locally\n",
    "\n",
    "Before deploying anything to the cloud, a crucial step is to test locally. This allows for rapid iteration and debugging.\n",
    "\n",
    "The A2aAgent class from the Vertex AI SDK is our deployable unit. It wraps our AgentCard and AgentExecutor together. Calling set_up() prepares an in-memory server, allowing us to simulate calls to the agent as if it were deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2a_agent = A2aAgent(agent_card=weather_agent_card, agent_executor_builder=WeatherAgentExecutor)\n",
    "a2a_agent.set_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('GOOGLE_GENAI_USE_VERTEXAI').lower() in ['true', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipiSUpCpfwNA"
   },
   "source": [
    "#### Get the agent card\n",
    "\n",
    "At this point, we can call the handle_authenticated_agent_card method on our local agent instance to simulate a client discovering our agent by requesting its \"business card.\" It would return the agent's capabilities, skills, and its endpoint URL, confirming our local server is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0hvJyJbf0rK"
   },
   "outputs": [],
   "source": [